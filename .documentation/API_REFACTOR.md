# API Refactoring Task List

This document outlines the necessary changes to refactor the MakeIt3D BFF API and related components. The primary goal is to streamline asset handling by making the client-generated `task_id` central, leveraging Supabase for input and output asset storage, and having the BFF create/update metadata records in dedicated Supabase tables (`input_assets`, `concept_images`, `models`).

## I. Core Principles for Refactoring

1.  **Client-Generated `task_id` is King**:
    *   A unique `task_id` is generated by the client at the start of any new generation workflow.
    *   This `task_id` is passed in every BFF request related to that job and is used for polling `GET /tasks/{task_id}/status` (for real-time AI service status).
    *   The client creates/manages records in the `input_assets` table, associating them with the `task_id`.

2.  **Inputs to BFF: Explicit Supabase Paths + `task_id`**:
    *   Client uploads primary input assets (images, sketches) to its Supabase storage first (e.g., a bucket like `user_input_files_bucket`).
    *   Client creates a record in the `input_assets` table, storing the `asset_url` for this uploaded file, linked to the `task_id`.
    *   Client's request to BFF includes the `task_id` AND the explicit full Supabase `asset_url` (from the `input_assets` table or `concept_images` table if chaining) for the specific input asset the BFF needs to process.
    *   BFF uses this explicit `asset_url` to fetch the asset from Supabase Storage.

3.  **BFF Places Outputs in Supabase Storage (Specific Path Structure)**:
    *   BFF downloads/retrieves generated assets from AI services.
    *   BFF uploads these assets to a structured location in a **configurable client Supabase Storage bucket** (e.g., `makeit3d_app_assets`).
    *   The path structure within the bucket will be: `{asset_type_plural}/{task_id}/{filename}`.
        *   `asset_type_plural`: `concepts` (for OpenAI images) or `models` (for TripoAI 3D models).
        *   `task_id`: The client-generated unique task identifier.
        *   `filename`: A standard name, e.g., `0.png`, `1.png` for concepts, or `model.glb` for 3D models.
    *   Example paths:
        *   `makeit3d_app_assets/concepts/task_abc123xyz/0.png`
        *   `makeit3d_app_assets/models/task_qrs789uvw/model.glb`

4.  **BFF Creates/Updates Metadata (including Status) in Dedicated Supabase Tables & Reports Output Locations**:
    *   Upon successful generation and upload of an output asset to Supabase Storage, the BFF **creates or updates a record** in the appropriate dedicated Supabase table (`concept_images` for OpenAI outputs, `models` for TripoAI outputs).
    *   This record will include:
        *   The `task_id`.
        *   The Supabase Storage `asset_url` of the generated file (full URL).
        *   The **`status` of the asset generation** ('pending', 'processing', 'complete'). The BFF manages this status, updating it as the process progresses for a given asset.
        *   The prompt, style, and other relevant metadata.
    *   The BFF's response from `GET /tasks/{task_id}/status` (for a specific AI step) will also include the current AI processing status and, upon completion of that step by the AI and subsequent upload by BFF, the direct, stable Supabase `asset_url`(s).
    *   The client primarily relies on querying the `input_assets`, `concept_images`, and `models` tables (filtered by `task_id` and observing the `status` column) for the persisted state and asset locations.

5.  **Configuration for BFF**:
    *   BFF will require new configuration settings for Supabase (URL, service key) and the names of the target tables: `CONCEPT_IMAGES_TABLE_NAME` and `MODELS_TABLE_NAME`, and the **name of the Supabase Storage bucket for generated assets** (e.g., `GENERATED_ASSETS_BUCKET_NAME`).

## II. Documentation Updates (`.documentation/`)

1.  **`makeit3d-api.md` (OpenAPI Specification)**:
    *   [x] Add a global note emphasizing the client-generated `task_id` requirement and that inputs are Supabase asset URLs.
    *   [x] **Request Schemas**:
        *   [x] `ImageToImageParams`: Add `task_id` (required), change `image` (binary) to `input_image_asset_url` (string, Supabase URL, required).
        *   [x] `TextToModelRequest`: Add `task_id` (required).
        *   [x] `ImageToModelRequest`: Add `task_id` (required), change `image_urls` to `input_image_asset_urls` (array of Supabase URLs, required).
        *   [x] `SketchToModelRequest`: Add `task_id` (required), change `image_url` to `input_sketch_asset_url` (string, Supabase URL, required).
        *   [x] `RefineModelRequest`: Add `task_id` (client's main workspace task_id, required), rename `draft_model_task_id` to `tripo_draft_task_id` (required).
        *   [x] Remove `SelectConceptRequest` schema.
    *   [x] **Response Schemas**:
        *   [x] `TaskIdResponse`: Clarify `task_id` is the one used for polling the current AI operation.
        *   [x] `TaskStatusResponse`: Clarify `result_url` and `result.image_urls` contain direct Supabase Storage URLs to assets produced by the current AI operation, and that the `status` field reflects the real-time AI processing status for *that specific step*.
    *   [x] **Paths**:
        *   [x] `/generate/image-to-image`: Change request content type to `application/json`. Update summary/description for `task_id` and `input_image_asset_url`.
        *   [x] All `/generate/*` endpoints: Update summaries/descriptions for `task_id` and new input asset URL parameters.
        *   [x] Remove `/generate/select-concept` path.
2.  **`bff_architecture.md` (BFF Internal Design)**:
    *   [x] Update **Overview & Core Logic** to reflect the 3-table Supabase model (`input_assets`, `concept_images`, `models`), client providing input asset URLs, BFF fetching inputs, BFF storing outputs to Supabase Storage (using the defined path structure `{asset_type_plural}/{task_id}/{filename}` within a configurable bucket), BFF creating/updating records (including `status`) in `concept_images` or `models` tables, and BFF reporting Supabase URLs and real-time AI status via `/tasks/{celery_task_id}/status`.
    *   [x] Update **API Endpoint Processing Details**:
        *   Detail fetching inputs from client-provided Supabase asset URLs.
        *   Detail storing outputs to Supabase Storage using the specified path structure.
        *   Detail creating/updating records (including `status` field progression and `celery_task_id` / `ai_provider_task_id` storage) in the `concept_images` or `models` tables with the new asset URL and metadata.
    *   [x] Update `/tasks/{celery_task_id}/status`: Clarify its role for real-time AI status for a specific Celery task (and subsequent Tripo AI polling if applicable), and providing immediate Supabase URLs for the step, complementing the persisted records (and their statuses) in the dedicated tables.
    *   [x] Update **Storage Interaction Section**: Detail BFF interaction with Supabase Storage (for assets, using the defined path structure) and specific Supabase tables (`concept_images`, `models`) for metadata (including status updates, `celery_task_id`, `ai_provider_task_id`).
    *   [x] Define requirements for the **Supabase Handler Module** to interact with these specific tables and Storage, including forming the correct storage paths and updating status fields.
    *   [x] Update **Directory Structure** to match implemented code (e.g., `task_status.py`, `celery_worker.py`, `app/tasks/generation_tasks.py`).
3.  **`frontend_architecture.md` (Frontend Internal Design & Flows)**:
    *   [x] Update to reflect client-generated `task_id`, client-managed Supabase tables (`input_assets`, `concept_images`, `models`), client providing Supabase URLs for inputs, and client polling `/tasks/{celery_task_id}/status` for real-time AI step status and final asset URLs.

## III. BFF Application Code Updates (`app/`)

1.  **Configuration (`app/config.py`)**:
    *   [x] Add/Verify Pydantic settings for Supabase URL and service key.
    *   [x] Add settings for table names: `INPUT_ASSETS_TABLE_NAME` (if BFF needs to read from it), `CONCEPT_IMAGES_TABLE_NAME`, `MODELS_TABLE_NAME`.
    *   [x] Add setting: `GENERATED_ASSETS_BUCKET_NAME` (e.g., "makeit3d_app_assets").
2.  **New/Updated Module: Supabase Handler (e.g., `app/supabase_handler.py`)**:
    *   [x] Implement Supabase client initialization.
    *   [x] Function: `fetch_asset_from_storage(asset_supabase_url: str) -> bytes`.
    *   [x] Function: `upload_asset_to_storage(bucket_name: str, task_id: str, asset_type_plural: str, asset_data: bytes, filename: str) -> str` (returns full Supabase Storage URL. `asset_type_plural` is 'concepts' or 'models'). Path constructed as `{asset_type_plural}/{task_id}/{filename}` inside the `bucket_name`.
    *   [x] Function: `create_concept_image_record(task_id: str, user_id: str, prompt: str, style: str, asset_url: str, status: str, ai_service_task_id: str, metadata: dict)` (initial status 'pending').
    *   [x] Function: `create_model_record(task_id: str, user_id: str, prompt: str, style: str, asset_url: str, status: str, ai_service_task_id: str, source_input_id: str = None, source_concept_id: str = None, metadata: dict)` (initial status 'pending').
    *   [x] Function: `update_asset_record_status_and_url(table_name: str, record_id_or_ai_task_id_or_task_id: str, status: str, asset_url: str = None, ai_service_task_id_for_update_filter: str = None)` (flexible update, e.g., update status to 'processing', then later to 'complete' and add `asset_url`).
3.  **Schemas (`app/schemas/*.py`)**:
    *   [x] Update Pydantic schemas per `makeit3d-api.md`.
    *   [x] Ensure `TaskStatusResponse` schema accurately reflects the fields for real-time AI step status.
4.  **Routers (`app/routers/generation.py`, `app/routers/models.py`)**:
    *   [x] Modify `/generate/*` endpoints:
        *   Accept `task_id` and input asset URLs.
        *   Call `supabase_handler.fetch_asset_from_storage()`.
        *   When initiating AI job, call `supabase_handler.create_concept_image_record()` or `create_model_record()` with an initial status 'pending' (then updated to 'processing' after Celery dispatch with Celery task ID).
        *   After AI processing & uploading output to Storage via `supabase_handler.upload_asset_to_storage()`:
            *   (Handled by Celery Tasks) Call `supabase_handler.update_asset_record_status_and_url()` to set status to 'complete' and store the final `asset_url` in the respective table (`concept_images` or `models`).
    *   [x] `/tasks/{task_id}/status`: Logic to query AI service. If the AI service indicates completion for this step, the BFF should then ensure the corresponding record in `concept_images` or `models` table is updated to 'complete' and has the `asset_url` (TripoAI flow correctly implements this; OpenAI flow relies on Celery task for final DB update, which is then read by this endpoint).
5.  **AI Clients (`app/ai_clients/*.py`)**:
    *   [x] No direct Supabase interaction. Accept raw data, return raw data/temp AI URLs.

## IV. BFF Test Updates (`tests/`)

1.  **Test Configuration & Mocks**:
    *   [x] Mock `supabase_handler.py` to simulate:
        *   Fetching from Supabase Storage.
        *   Uploading to Supabase Storage (verify correct path formation: `bucket_name/asset_type_plural/task_id/filename`).
        *   Creating records in `concept_images` and `models` tables with initial status.
        *   Updating records in `concept_images` and `models` tables with final status and asset URL.
2.  **Test Cases for `/routers/*.py`**:
    *   [x] Verify new request formats with Supabase asset URLs.
    *   [x] Mock `fetch_asset_from_storage` calls.
    *   [x] Assert `upload_asset_to_storage` calls with correct bucket, path components, and data.
    *   [x] Assert `create_concept_image_record` or `create_model_record` calls with correct initial status.
    *   [x] Assert `update_asset_record_status_and_url` calls with correct final status and asset URL.

## V. Supabase Schema (SQL for reference - ensure these are applied)

```sql
-- Ensure uuid-ossp extension is enabled
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

CREATE TABLE input_assets (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    task_id TEXT NOT NULL,
    user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
    prompt TEXT,
    style TEXT,
    input_asset_type TEXT NOT NULL, -- e.g., 'text_prompt', 'uploaded_photo', 'uploaded_sketch'
    asset_url TEXT, -- URL to the asset in Supabase storage
    status TEXT NOT NULL DEFAULT 'pending',
    created_at TIMESTAMPTZ DEFAULT now(),
    metadata JSONB
);
-- ... (indexes and RLS for input_assets)

CREATE TABLE concept_images (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    task_id TEXT NOT NULL,
    user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
    source_input_asset_id UUID REFERENCES input_assets(id) ON DELETE SET NULL,
    prompt TEXT NOT NULL,
    style TEXT,
    asset_url TEXT, -- Full URL to the generated concept image in Supabase storage e.g. https://[project_ref].supabase.co/storage/v1/object/public/makeit3d_app_assets/concepts/task_abc123xyz/0.png. Will be NULL until generation is complete.
    status TEXT NOT NULL DEFAULT 'pending', -- 'pending', 'processing', 'complete'
    ai_service_task_id TEXT,
    created_at TIMESTAMPTZ DEFAULT now(),
    metadata JSONB
);
-- ... (indexes and RLS for concept_images)

CREATE TABLE models (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    task_id TEXT NOT NULL,
    user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
    source_input_asset_id UUID REFERENCES input_assets(id) ON DELETE SET NULL,
    source_concept_image_id UUID REFERENCES concept_images(id) ON DELETE SET NULL,
    prompt TEXT NOT NULL,
    style TEXT,
    asset_url TEXT, -- Full URL to the generated 3D model in Supabase storage e.g. https://[project_ref].supabase.co/storage/v1/object/public/makeit3d_app_assets/models/task_qrs789uvw/model.glb. Will be NULL until generation is complete.
    status TEXT NOT NULL DEFAULT 'pending', -- 'pending', 'processing', 'complete'
    ai_service_task_id TEXT,
    created_at TIMESTAMPTZ DEFAULT now(),
    metadata JSONB
);
-- ... (indexes and RLS for models)
```

*(Note: Full RLS policies and indexes from previous SQL generation should be included in the final schema implementation)* 